// Copyright 2024 Luis Hsu
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     https://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <ParGen.hpp>
#include <Util.hpp>
#include <exception.hpp>

#include <map>
#include <set>
#include <deque>
#include <vector>
#include <memory>
#include <numeric>
#include <fstream>
#include <sstream>
#include <regex>
#include <cmath>
#include <algorithm>
#include <unordered_set>

#include "parser.hpp"

void Pargen::Parser::generate_header(std::ostream& os){
    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    {
        std::string guard = class_name;
        std::replace(guard.begin(), guard.end(), ':', '_');
        os << "#ifndef ParGen_" << guard << "_guard" << std::endl;
        os << "#define ParGen_" << guard << "_guard" << std::endl;
    }
    os << header_prologue << std::endl;

    os << "#include <map>" << std::endl;
    os << "#include <set>" << std::endl;
    os << "#include <list>" << std::endl;
    os << "#include <string>" << std::endl;
    os << "#include <utility>" << std::endl;
    os << "#include <vector>" << std::endl;
    os << "#include <optional>" << std::endl;
    os << "#include <initializer_list>" << std::endl;
    if(!parent.tokens.empty()){
        os << "#include " << parent.tokens.header_path.filename() << std::endl;
    }
    if(parent.lexer.empty()){
        os << "#include <any>" << std::endl;
    }else{
        os << "#include " << parent.lexer.header_path.filename() << std::endl;
    }

    // pargen namespace
    os << "\nnamespace " << parent.name_space << " {\n" << std::endl;

    // Parser class
    os << "struct " << class_name << " {" << std::endl;
    os << "    " << class_name << "(" << parent.lexer.class_name << "& lexer);" << std::endl;
    os << "    " << return_type << " parse();" << std::endl;
    // Funcs
    for(std::string& func : functions){
        os << func << std::endl;
    }

    size_t term_type = sizeof(size_t);
    {
        TermMap term_map(*this);
        term_type = std::pow(2, std::ceil(std::log2(std::ceil(std::log2(term_map.size()) / CHAR_BIT)))) * CHAR_BIT;
    }
    
    // Members
    for(std::string& member : members){
        os << member << std::endl;
    }
    os << "    constexpr static size_t End = (size_t)-1;" << std::endl;
    os << "    using term_t = uint" << term_type << "_t";
    os << ";" << std::endl;
    if(parent.lexer.empty()){
        os << "    using token_t = std::any;" << std::endl;
        os << "protected:" << std::endl;
    }else{
        if(parent.lexer.return_type.empty()){
            if(parent.tokens.empty()){
                os << "    using token_t = std::any;" << std::endl;
            }else{
                os << "    using token_t = " << parent.tokens.class_name << ";" << std::endl;
            }
        }else{
            os << "    using token_t = " << parent.lexer.return_type << ";" << std::endl;
        }
        os << "protected:" << std::endl;
        os << "    " << parent.lexer.class_name << "& lexer;" << std::endl;
    }
    os << "    using Act = std::pair<size_t, std::vector<bool>>;" << std::endl;
    os << "    using State = std::map<term_t, std::vector<Act>>;" << std::endl;
    os << "    struct Entry;" << std::endl;
    os << "    struct Node {" << std::endl;
    os << "        size_t action;" << std::endl;
    os << "        std::vector<bool> param_toggle;" << std::endl;
    os << "        std::list<Entry> children;" << std::endl;
    os << "        std::list<std::pair<term_t,token_t>> flatten();" << std::endl;
    os << "    };" << std::endl;
    os << "    struct Entry {" << std::endl;
    if(parent.options.dump_tree){
        os << "        static size_t serial;" << std::endl;
        os << "        size_t id;" << std::endl;
    }
    os << "        term_t term;" << std::endl;
    os << "        size_t state;"  << std::endl;
    os << "        size_t branch = 0;"  << std::endl;
    os << "        std::variant<std::monostate, Node, token_t> elem;"  << std::endl;
    os << "    };" << std::endl;
    os << "    struct Stack : public std::list<Entry>{" << std::endl;
    os << "        void push(std::pair<term_t,token_t> token, size_t state){" << std::endl;
    os << "            emplace_front(Entry {";
    if(parent.options.dump_tree){
        os << ".id = Entry::serial++, ";
    }
    os << ".term = token.first, .state = state, .elem = token.second});" << std::endl;
    os << "        }" << std::endl;
    os << "        void reduce(size_t action, std::vector<bool> param_toggle);" << std::endl;
    os << "    };\n" << std::endl;
    os << "    std::list<std::pair<term_t,token_t>> buffer;" << std::endl;
    os << "    static std::vector<State> table;" << std::endl;
    os << "    std::pair<term_t,token_t> fetch();" << std::endl;
    os << "    " << return_type << " expand_tree(Entry&);" << std::endl;
    if(parent.options.dump_tree){
        os << "    void dump_tree(Entry&);" << std::endl;
    }
    os << "};\n" << std::endl;

    // Parse error
    os << "struct ParseError : public std::exception {" << std::endl;
    os << "    ParseError(" << class_name << "::term_t term);" << std::endl;
    os << "    std::string msg;" << std::endl;
    os << "    const char* what(){" << std::endl;
    os << "        return msg.c_str();" << std::endl;
    os << "    }" << std::endl;
    os << "};\n" << std::endl;

    // close namespace
    os << "} // namespace " << parent.name_space << std::endl;

    // epilogue
    os << header_epilogue << std::endl;
    os << "#endif " << std::endl;
}

void Pargen::Parser::generate_source(std::ostream& os){

    // Create GLR parser
    GLRParser parser(*this);

    // dump terms
    if(parent.options.debug){
        std::ofstream fout("terms.txt");
        parser.dump_terms(fout);
        fout.close();
    }

    // dump grammars
    if(parent.options.debug){
        std::ofstream fout("grams.txt");
        parser.dump_grammars(fout);
        fout.close();
    }

    // dump states
    if(parent.options.debug){
        std::ofstream fout("states.dot");
        parser.dump_states(fout);
        fout.close();
    }

    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    os << "#include " << header_path << std::endl;
    os << source_prologue << std::endl;

    // includes & namespace
    os << "#include <stack>" << std::endl;
    os << "#include <list>" << std::endl;
    os << "#include <variant>" << std::endl;
    os << "#include <vector>" << std::endl;
    os << "#include <algorithm>" << std::endl;
    os << "#include <array>" << std::endl;
    if(parent.options.dump_tree){
        os << "#include <fstream>" << std::endl;
        os << "#include <queue>" << std::endl;
        os << "#include <map>" << std::endl;
    }

    os << "\nnamespace " << parent.name_space << " {" << std::endl;
    if(!parent.tokens.empty()){
        os << "\nusing namespace " << parent.tokens.name_space << ";\n" << std::endl;
    }

    // constructor
    os << class_name << "::" << class_name << "(" << parent.lexer.class_name << "& lexer) : lexer(lexer) {}\n" << std::endl;

    // Dump tree 
    if(parent.options.dump_tree){
        os << "size_t " << class_name << "::Entry::serial = 0;" << std::endl;
        os << "void " << class_name << "::dump_tree(" << class_name << "::Entry& tree){\n"
                "    static std::map<term_t, std::string> term_map {\n";
        for(auto term_pair : parser.term_map){
            os << "        {" << term_pair.second << ",\"" << term_pair.first << "\"},\n";
        }
        os << "    };\n";
        os << "    std::ofstream fout(\"tree.dot\");\n"
            "    fout << \"graph {\" << std::endl;\n"
            "    std::queue<Entry> node_queue;\n"
            "    node_queue.push(tree);\n"
            "    while(!node_queue.empty()){\n"
            "        Entry& entry = node_queue.front();\n"
            "        fout << \"E\" << entry.id << \" [label=\\\"\" << term_map[entry.term] << \"\\\"];\" << std::endl;\n"
            "        if(std::holds_alternative<Node>(entry.elem)){\n"
            "            Node& node = std::get<Node>(entry.elem);\n"
            "            for(auto it = node.children.begin(); it != node.children.end(); ++it){\n"
            "                fout << \"E\" << entry.id << \" -- E\" << it->id << std::endl;\n"
            "                node_queue.emplace(*it);\n"
            "            }\n"
            "        }\n"
            "        node_queue.pop();\n"
            "    }\n"
            "    fout << \"}\";\n"
            "    fout.close();\n"
            "}\n";
    }

    // fetch
    os << "std::pair<" << class_name << "::term_t, " << class_name << "::token_t> " << class_name << "::fetch(){" << std::endl;
    os << "    if(!buffer.empty()){" << std::endl;
    os << "        auto token = buffer.front();" << std::endl;
    os << "        buffer.pop_front();" << std::endl;
    os << "        return token;" << std::endl;
    os << "    }" << std::endl;
    if(!parent.lexer.empty() && parent.lexer.return_type.empty() && !parent.tokens.empty()){
        os << "    " << parent.tokens.class_name << " res = lexer.get();" << std::endl;
        os << "    return {res.index() + 1, res};" << std::endl;
    }else{
        os << "    /* TODO: return pair as below:" << std::endl;
        std::unordered_set<std::string> nterms;
        std::transform(begin(), end(), std::inserter(nterms, nterms.end()), [](Pargen::Grammar& gram){
            return gram.target;
        });
        for(auto term_pair : parser.term_map){
            if(!nterms.contains(term_pair.first)){
                os << "      {" << term_pair.second << ", " << term_pair.first << "}" << std::endl;
            }
        }
        os << "    */" << std::endl;
    }
    os << "}\n" << std::endl;

    // actions
    std::set<std::string> returns;
    for(size_t action_id = 0; action_id < parser.actions.size(); ++action_id){
        GLRParser::Action& action = parser.actions[action_id];
        std::string return_type = parser.type_map[action.result];
        if(return_type.empty()){
            return_type = "void";
        }else{
            returns.insert(return_type);
        }
        os << "static " << return_type << " action_"<< action_id + 1 << "(";
        bool has_first = false;
        if(!parent.tokens.empty()){
            os << "std::vector<Position> _pos";
            has_first = true;
        }
        for(size_t param_id = 0; param_id < action.params.size(); ++param_id){
            term_t term = action.params[param_id];
            if(!parser.term_map.is_term(term) && parser.type_map[term].empty()){
                continue;
            }
            if(has_first){
                os << ", ";
            }else{
                has_first = true;
            }
            if(parser.term_map.is_term(term)){
                os << parent.tokens.name_space << "::" << parser.term_map[term].value();
            }else{
                os << parser.type_map[term];
            }
            os << " _op" << param_id;
        }
        os << "){" << action.body << "\n}" << std::endl;
    }
    os << std::endl;

    // table
    os << "std::vector<" << class_name << "::State> " << class_name << "::table = {" << std::endl;
    for(const GLRParser::State& state : parser.states){
        std::map<term_t, std::list<std::pair<size_t, std::vector<bool>>>> acts;
        // Shift
        for(const std::pair<const term_t, size_t>& edge : state.edges){
            acts[edge.first].emplace_back((edge.second << 1) + 1, std::vector<bool>{});
        }
        // Reduce
        for(const GLRParser::Grammar& prod : state.productions){
            if(prod.dot_pos == prod.depends.size()){
                for(term_t lookahead : prod.lookahead){
                    acts[lookahead].emplace_back((prod.action << 1) & ((size_t)~1), prod.param_toggle);
                }
            }
        }
        // Output state
        os << "    {";
        for(auto act_pair : acts){
            // Term
            os << "{" << act_pair.first << ", {";
            for(std::pair<size_t, std::vector<bool>> act : act_pair.second){
                os << "{" << act.first << ",";
                os << "{";
                for(bool toggle : act.second){
                    os << toggle << ",";
                }
                os << "}";
                os << "},";
            }
            os << "}},";
        }
        os << "}," << std::endl;
    }
    os << "};\n" << std::endl;

    // parse
    os << return_type << " " << class_name << "::parse(){\n"
        "    // Prepare\n"
        "    std::stack<Stack::iterator> branches;\n"
        "    Stack stack;\n"
        "    stack.push(fetch(), 0);\n"
        "    auto throw_error = [&](term_t term){\n"
        "        if(branches.empty()){\n"
        "            throw ParseError(term);\n"
        "        }\n"
        "        auto& saved = branches.top();\n"
        "        auto buf_top = buffer.begin();\n"
        "        for(auto it = stack.begin(); it != saved; it = std::next(it)){\n"
        "            if(std::holds_alternative<token_t>(it->elem)){\n"
        "                buffer.emplace(buf_top, it->term, std::get<token_t>(it->elem));\n"
        "            }else{\n"
        "                auto flattened = std::get<Node>(it->elem).flatten();\n"
        "                buffer.insert(buf_top, flattened.begin(), flattened.end());\n"
        "            }\n"
        "        }\n"
        "        saved->branch += 1;\n"
        "    };\n"
        "    // Parse\n"
        "    while(stack.front().state != End){\n"
        "        Entry& entry = stack.front();\n"
        "        State& state = table[entry.state];\n"
        "        if(state.contains(entry.term)){\n"
        "            std::vector<Act>& acts = state[entry.term];\n"
        "            if(entry.branch == 0){\n"
        "                if(acts.size() > 1){\n"
        "                    branches.emplace(stack.begin());\n"
        "                }\n"
        "            }else if(entry.branch == acts.size() - 1){\n"
        "                branches.pop();\n"
        "            }\n"
        "            Act& act = acts[entry.branch];\n"
        "            if(act.first & 1){ // Shift\n"
        "                stack.push(fetch(), act.first >> 1);\n"
        "            }else{ // Reduce\n"
        "                if(std::holds_alternative<token_t>(entry.elem)){\n"
        "                    buffer.emplace_front(entry.term, std::get<token_t>(entry.elem));\n"
        "                    stack.pop_front();\n"
        "                }\n"
        "                stack.reduce(act.first >> 1, act.second);\n"
        "            }\n"
        "        }else{\n"
        "            throw_error(entry.term);\n"
        "        }\n"
        "    }\n";
    if(parent.options.dump_tree){
        os << "    // Dump tree\n"
            "    dump_tree(stack.back());\n";
    }
    os << "    // Expand tree\n"
        "    return expand_tree(stack.back());\n";
    os << "}\n" << std::endl;

    // reduce
    os << "void " << class_name << "::Stack::reduce(size_t action, std::vector<bool> param_toggle){" << std::endl;
    os << "    static const std::vector<term_t> signatures {";
    for(GLRParser::Action& action : parser.actions){
        os << action.result << ",";
    }
    os << "};" << std::endl;
    os << "    if(action == 0){\n"
        "        emplace_front(Entry {.term = 0, .state = End});\n"
        "        return;\n"
        "    }\n"
        "    Node node = {.action = action, .param_toggle = param_toggle};\n"
        "    size_t param_count = std::count_if(param_toggle.begin(), param_toggle.end(), [](bool val){return val;});\n"
        "    for(size_t i = 0; i < param_count; ++i){\n"
        "        node.children.emplace_front(front());\n"
        "        pop_front();\n"
        "    }\n"
        "    Entry* head = &node.children.front();\n"
        "    while(std::holds_alternative<Node>(head->elem)){\n"
        "        Node& child = std::get<Node>(head->elem);\n"
        "        head = &child.children.front();\n"
        "    }\n"
        "    Entry& entry = emplace_front();\n";
    if(parent.options.dump_tree){
        os << "    entry.id = Entry::serial++;\n";
    }
    os << "    entry.term = signatures[action - 1];\n"
        "    entry.state = head->state;\n"
        "    entry.elem.emplace<Node>(node);\n";
    os << "}\n" << std::endl;

    // stack item
    os << "using item_t = std::variant<std::monostate,\n"
        "    " << class_name << "::token_t,\n";
    for(auto it = returns.begin(); it != returns.end(); it = std::next(it)){
        os << "    " << *it;
        if(std::next(it) != returns.end()){
            os << ",";
        }
        os << std::endl;
    }
    os << ">;\n" << std::endl;
    
    // expand tree
    os << return_type << " " << class_name << "::expand_tree(Entry& tree){" << std::endl;
    os << "    std::list<std::variant<Node, token_t>> entry_stack;\n"
        "    std::list<std::pair<Position, item_t>> param_stack;\n"
        "    auto extract_entry = [&](Entry& entry){\n"
        "        if(std::holds_alternative<token_t>(entry.elem)){\n"
        "            entry_stack.emplace_front(std::get<token_t>(entry.elem));\n"
        "        }else if(std::holds_alternative<Node>(entry.elem)){\n"
        "            Node& elem = std::get<Node>(entry.elem);\n"
        "            Node& node = std::get<Node>(entry_stack.emplace_front(Node {.action = elem.action, .param_toggle = elem.param_toggle}));\n"
        "            node.children.swap(elem.children);\n"
        "        }\n"
        "    };\n"
        "    extract_entry(tree);\n";

        // invoke action
    os << "    auto invoke_action = [&](Node& node){\n"
        "        std::vector<Position> positions(node.param_toggle.size());\n"
        "        std::vector<item_t> params(node.param_toggle.size());\n"
        "        Position pos;\n"
        "        for(size_t i = node.param_toggle.size(); i > 0; --i){\n"
        "            size_t index = i - 1;\n"
        "            if(node.param_toggle[index]){\n"
        "                positions[index] = param_stack.front().first;\n"
        "                params[index] = param_stack.front().second;\n"
        "                param_stack.pop_front();\n"
        "            }\n"
        "        }\n"
        "        for(size_t i = 0; i < node.param_toggle.size(); ++i){\n"
        "            if(node.param_toggle[i]){\n"
        "                pos = positions[i];\n"
        "                break;\n"
        "            }\n"
        "        }\n"
        "        switch(node.action){\n";
    for(size_t action_id = 0; action_id < parser.actions.size(); ++action_id){
        GLRParser::Action& action = parser.actions[action_id];
        bool is_void = parser.type_map[action.result].empty();
        os << "            case " << action_id + 1 << ": " << std::endl;
        os << "                param_stack.emplace_front(pos, ";
        if(is_void){
            os << "std::monostate());\n"
                << "                ";
        }
        os << "action_" << action_id + 1 << "(positions";
        for(size_t param_id = 0; param_id < action.params.size(); ++param_id){
            term_t term = action.params[param_id];
            std::string type;
            bool is_term = false;
            if(parser.term_map.is_term(term)){
                type = parent.tokens.name_space + "::" + parser.term_map[term].value();
                is_term = true;
            }else{
                type = parser.type_map[term];
            }
            if(!type.empty()){
                os << ",\n";
                os << "                    node.param_toggle[" << param_id << "] ? std::get<" << type
                    << ">(";
                if(is_term){
                    os << "std::get<Token>(params[" << param_id << "]))";
                }else{
                    os << "params[" << param_id << "])";
                }
                os << " : " << type << "()";
            }
        }
        os << "\n                )";
        if(is_void){
            os << ";" << std::endl;
        }else{
            os << ");" << std::endl;
        }
        os << "            break;" << std::endl;
    }
    os << "            default:\n"
        "            break;\n"
        "        }\n"
        "    };\n";
    os << "    while(!entry_stack.empty()){\n"
        "        std::variant<Node, token_t>& entry = entry_stack.front();\n"
        "        if(std::holds_alternative<token_t>(entry)){\n"
        "            token_t token = std::get<token_t>(entry);\n"
        "            param_stack.emplace_front(token.pos, token);\n"
        "            entry_stack.pop_front();\n"
        "        }else if(std::holds_alternative<Node>(entry)){\n"
        "            Node& node = std::get<Node>(entry);\n"
        "            if(node.children.size() > 0){\n"
        "                for(auto it = node.children.rbegin(); it != node.children.rend(); it = std::next(it)){\n"
        "                    extract_entry(*it);\n"
        "                }\n"
        "                node.children.clear();\n"
        "            }else{\n"
        "                invoke_action(node);\n"
        "                entry_stack.pop_front();\n"
        "            }\n"
        "        }\n"
        "    }\n";
    if(return_type != "void"){
        os << "    return std::get<" << return_type << ">(param_stack.front().second);" << std::endl;
    }
    os << "}\n" << std::endl;

    // functions
    for(std::string func : functions){
        // Write function
        std::string signature = append_func_name(func, class_name);
        if(signature.starts_with("template")){
            os << "// TODO: " << signature << "\n" << std::endl;
        }else{
            os << signature << "{" << std::endl;
            os << "    // TODO: implement function here" << std::endl;
            os << "}\n" << std::endl;
        }
    }

    // flatten
    os << "std::list<std::pair<" << class_name << "::term_t," << class_name << "::token_t>> " << class_name << "::Node::flatten(){" << std::endl;
    os << "    std::list<std::pair<term_t,token_t>> results;" << std::endl;
    os << "    for(Entry& child : children){" << std::endl;
    os << "        if(std::holds_alternative<token_t>(child.elem)){" << std::endl;
    os << "            results.emplace_back(child.term, std::get<token_t>(child.elem));" << std::endl;
    os << "        }else{" << std::endl;
    os << "            auto flattened = std::get<Node>(child.elem).flatten();" << std::endl;
    os << "            results.insert(results.end(), flattened.begin(), flattened.end());" << std::endl;
    os << "        }" << std::endl;
    os << "    }" << std::endl;
    os << "    return results;" << std::endl;
    os << "}\n" << std::endl;

    // parse error
    std::vector<std::pair<std::string, term_t>> term_list(parser.term_map.begin(), parser.term_map.end());
    std::sort(term_list.begin(), term_list.end(),
        [](const std::pair<std::string, term_t>& lhs, const std::pair<std::string, term_t>& rhs){
            return lhs.second < rhs.second;
        }
    );
    os << parent.name_space << "::ParseError::ParseError(" << class_name << "::term_t term){" << std::endl;
    os << "    static const std::vector<std::string> terms {" << std::endl;
    for(auto term_pair : term_list){
        os << "        \"" << term_pair.first << "\"," << std::endl;
    }
    os << "    };" << std::endl;
    os << "    msg = \"unexpected \" + terms[term];" << std::endl;
    os << "}" << std::endl;

    // close namespace
    os << "} // namespace " << parent.name_space << "\n" << std::endl;

    // epilogue
    os << source_epilogue << std::endl;
}

GLRParser::GLRParser(Pargen::Parser& parser) : term_map(parser), parser(parser) {
    // Prepare grammar
    read_grammar();
    std::map<term_t, std::set<term_t>> first_sets = create_first_sets();
    
    // Create grammar map
    std::map<term_t, std::set<Grammar>> gram_map;
    for(Grammar gram : grammars){
        gram_map[gram.target].insert(gram);
    }

    // Create states
    if(term_map[parser.start] == TermMap::none){
        throw Exception::Exception("can't find grammar for start");
    }
    std::deque<std::set<Grammar>> gram_queue {{Grammar {
        .target = TermMap::start,
        .depends = {term_map[parser.start]},
        .lookahead = {TermMap::eof}
    }}};
    std::list<State> state_list;
    {
        std::set<Grammar> created;
        while(!gram_queue.empty()){
            State state(gram_queue.front(), gram_map, first_sets);
            gram_queue.pop_front();
            std::map<term_t, std::set<Grammar>> prod_map;
            for(Grammar gram : state.productions){
                if(!created.contains(gram)){
                    if(gram.dot_pos != 0){
                        created.emplace(gram);
                    }
                    if(gram.dot_pos != gram.depends.size()){
                        size_t pos = gram.dot_pos;
                        gram.dot_pos += 1;
                        prod_map[gram.depends[pos]].emplace(gram);
                    }
                }
            }
            for(auto prod_pair : prod_map){
                gram_queue.push_back(prod_pair.second);
            }
            state_list.emplace_back(state);
        }
    }
    
    // Merge states
    bool modified = true;
    std::vector<std::list<State>::iterator> removed;
    while(modified){
        modified = false;
        size_t state_id = 0;
        for(auto lhs = state_list.begin(); lhs != state_list.end(); lhs = std::next(lhs)){
            if(std::find(removed.begin(), removed.end(), lhs) == removed.end()){
                for(auto rhs = state_list.begin(); rhs != state_list.end(); rhs = std::next(rhs)){
                    if((lhs != rhs)
                        && (std::find(removed.begin(), removed.end(), rhs) == removed.end())
                        && lhs->merge(*rhs)
                    ){
                        modified = true;
                        if(std::none_of(removed.begin(), removed.end(), [&](std::list<State>::iterator& elem){
                            return elem == rhs;
                        })){
                            removed.emplace_back(rhs);
                        }
                        break;
                    }
                }
                state_id += 1;
            }
        }
    }
    for(auto rem : removed){
        state_list.erase(rem);
    }
    states.assign(state_list.begin(), state_list.end());
    state_list.clear();
    removed.clear();

    // Create edges
    std::list<std::pair<Grammar, size_t>> edge_list;
    for(size_t state_id = 0; state_id < states.size(); ++state_id){
        State& state = states[state_id];
        for(Grammar& gram : state.productions){
            if(gram.dot_pos != 0){
                edge_list.emplace_back(gram, state_id);
            }
        }
    }
    for(State& state : states){
        std::set<term_t> linked;
        for(Grammar prod : state.productions){
            if(prod.dot_pos < prod.depends.size()){
                term_t term = prod.depends[prod.dot_pos];
                prod.dot_pos += 1;
                if(!linked.contains(term)){
                    for(auto edge_pair : edge_list){
                        Grammar& edge_gram = edge_pair.first;
                        if((edge_gram.target == prod.target) && (edge_gram.dot_pos == prod.dot_pos) && (edge_gram.depends == prod.depends)
                            && std::includes(edge_gram.lookahead.begin(), edge_gram.lookahead.end(), prod.lookahead.begin(), prod.lookahead.end())
                        ){
                            state.edges[term] = edge_pair.second;
                            linked.emplace(term);
                            break;
                        }
                    }
                }
            }
        }
    }
}

TermMap::TermMap(Pargen::Parser& parser){
    // Collect terminals
    std::set<std::string> terms, nterms;
    {
        std::set<std::string> all_terms;
        for(Pargen::Grammar gram : parser){
            nterms.insert(gram.target);
            all_terms.insert(gram.depends.begin(), gram.depends.end());
        }
        std::set_difference(all_terms.begin(), all_terms.end(), nterms.begin(), nterms.end(), std::inserter(terms, terms.end()));
    }

    // Assign term_map
    if(parser.parent.tokens.empty()){
        num_term = terms.size() + items.size();
        for(std::string term : terms){
            items.emplace(term, items.size());
        }
    }else{
        num_term = parser.parent.tokens.size() + items.size();
        for(Pargen::Token& token : parser.parent.tokens){
            items.emplace(token.name, items.size());
        }
    }
    for(std::string nterm : nterms){
        items.emplace(nterm, items.size());
    }
}

void GLRParser::read_grammar(){
    // Read grammars
    std::set<term_t> empties;
    for(Pargen::Grammar& gram : parser){
        // target
        term_t target = term_map[gram.target];
        if(target == TermMap::none){
            throw Exception::Exception("unknown terminal '" + gram.target + "'");
        }
        // action
        Action& action = actions.emplace_back();
        action.result = target;
        if(!type_map.contains(target)){
            type_map[target] = gram.type;
        }
        action.body = gram.content;
        // grammar
        if(gram.depends.empty()){
            // Empty grammar
            if(empties.contains(target)){
                throw Exception::Exception("multiple empty grammar for '" + gram.target + "'");
            }
            empties.emplace(target);
        }else{
            Grammar grammar;
            grammar.target = target;
            grammar.action = actions.size();
            std::transform(gram.depends.begin(), gram.depends.end(), std::back_inserter(grammar.depends), [&](std::string& dep){
                if(term_map[dep] == TermMap::none){
                    throw Exception::Exception("unknown terminal '" + dep + "'");
                }
                return term_map[dep];
            });
            action.params.assign(grammar.depends.begin(), grammar.depends.end());
            grammar.param_toggle.resize(grammar.depends.size(), true);
            grammars.emplace_back(grammar);
        }
    }

    // Expand empty grammar
    for(auto gram_it = grammars.begin(); gram_it != grammars.end(); gram_it = std::next(gram_it)){
        Grammar gram = *gram_it;
        for(size_t dep_idx = 0; dep_idx < gram.depends.size(); ++dep_idx){
            if(empties.contains(gram.depends[dep_idx])){
                Grammar new_gram = gram;
                new_gram.depends.erase(new_gram.depends.begin() + dep_idx);
                new_gram.param_toggle[dep_idx] = false;
                if((new_gram.depends.size() > 1 || (new_gram.depends.size() == 1 && new_gram.target != new_gram.depends[0]))
                    && (std::find(grammars.begin(), grammars.end(), new_gram) == grammars.end())
                ){
                    grammars.emplace_back(new_gram);
                }
            }
        }
    }
}

std::map<term_t, std::set<term_t>> GLRParser::create_first_sets(){
    std::map<term_t, std::set<term_t>> first_sets;
    // Insert terminals
    for(auto term_pair : term_map){
        if(!term_pair.first.empty() && term_map.is_term(term_pair.second)){
            first_sets[term_pair.second].emplace(term_pair.second);
        }
    }

    // Initialize non-terminals
    std::set<term_t> modified;
    for(const GLRParser::Grammar& gram : grammars){
        if(term_map.is_term(gram.depends.front())){
            modified.emplace(gram.target);
            first_sets[gram.target].emplace(gram.depends.front());
        }
    }

    // Update non-terminals
    while(!modified.empty()){
        std::set<term_t> checking = modified;
        modified.clear();
        for(const GLRParser::Grammar& gram : grammars){
            if(checking.contains(gram.depends.front())){
                for(term_t term : first_sets[gram.depends.front()]){
                    if(!first_sets[gram.target].contains(term)){
                        modified.emplace(gram.target);
                        first_sets[gram.target].emplace(term);
                    }
                }
            }
        }
    }
    return first_sets;
}

GLRParser::State::State(std::set<Grammar> grammars, std::map<term_t, std::set<Grammar>>& gram_map, std::map<term_t, std::set<term_t>>& first_sets){
    // Insert grammar
    std::list<Grammar> produced(grammars.begin(), grammars.end());
    productions.insert(productions.end(), grammars.begin(), grammars.end());
    std::map<term_t, std::set<term_t>> lookaheads;
    for(Grammar& prod : productions){
        if(prod.dot_pos < prod.depends.size()){
            if(prod.dot_pos == prod.depends.size() - 1){
                lookaheads[prod.depends[prod.dot_pos]].insert(prod.lookahead.begin(), prod.lookahead.end());
            }else{
                std::set<term_t>& first = first_sets[prod.depends[prod.dot_pos + 1]];
                lookaheads[prod.depends[prod.dot_pos]].insert(first.begin(), first.end());
            }
        }
    }
    // Expand productions
    for(Grammar grammar : grammars){
        if(grammar.dot_pos != grammar.depends.size()){
            for(Grammar& prod : productions){
                // produce grammar
                for(Grammar gram : gram_map[prod.depends[prod.dot_pos]]){
                    // lookahead
                    if(lookaheads.contains(gram.target)){
                        gram.lookahead = lookaheads[gram.target];
                    }else{
                        gram.lookahead = prod.lookahead;
                    }
                    std::list<Grammar>::iterator found = std::find_if(productions.begin(), productions.end(), [&](Grammar rhs){
                        return (gram.target == rhs.target) && (gram.dot_pos == rhs.dot_pos) && (gram.depends == rhs.depends);
                    });
                    if(found == productions.end()){
                        produced.emplace_back(gram);
                        productions.emplace_back(gram);
                        if(gram.dot_pos == gram.depends.size() - 1){
                            lookaheads[gram.depends[gram.dot_pos]].insert(gram.lookahead.begin(), gram.lookahead.end());
                        }else{
                            std::set<term_t>& first = first_sets[gram.depends[gram.dot_pos + 1]];
                            lookaheads[gram.depends[gram.dot_pos]].insert(first.begin(), first.end());
                        }
                    }else{
                        found->lookahead.insert(gram.lookahead.begin(), gram.lookahead.end());
                    }
                }
            }
        }
    }
}

bool GLRParser::State::merge(State& state){
    const auto comp = [](const Grammar& lhs, const Grammar& rhs){
        return (lhs.target == rhs.target) && (lhs.dot_pos == rhs.dot_pos) && (lhs.depends == rhs.depends);
    };
    std::list<std::pair<Grammar*, Grammar*>> merge_pairs;
    for(Grammar& prod_l : state.productions){
        bool found = false;
        for(Grammar& prod_r : productions){
            if(comp(prod_l, prod_r)){
                found = true;
                merge_pairs.emplace_back(&prod_r, &prod_l);
                break;
            }
        }
        if(!found){
            return false;
        }
    }
    for(auto merge_pair : merge_pairs ){
        merge_pair.first->lookahead.insert(merge_pair.second->lookahead.begin(), merge_pair.second->lookahead.end());
    }
    return true;
}

bool operator<(const GLRParser::Grammar& lhs, const GLRParser::Grammar& rhs){
    if(lhs.target != rhs.target){
        return lhs.target < rhs.target;
    }
    if(lhs.depends.size() != rhs.depends.size()){
        return lhs.depends.size() < rhs.depends.size();
    }
    for(size_t i = 0; i < lhs.depends.size(); ++i){
        if(lhs.depends[i] != rhs.depends[i]){
            return lhs.depends[i] < rhs.depends[i];
        }
    }
    if(lhs.dot_pos != rhs.dot_pos){
        return lhs.dot_pos < rhs.dot_pos;
    }
    if(lhs.lookahead.size() != rhs.lookahead.size()){
        return lhs.lookahead.size() < rhs.lookahead.size();
    }
    std::vector<term_t> look_l(lhs.lookahead.begin(), lhs.lookahead.end());
    std::sort(look_l.begin(), look_l.end());
    std::vector<term_t> look_r(rhs.lookahead.begin(), rhs.lookahead.end());
    std::sort(look_r.begin(), look_r.end());
    for(size_t i = 0; i < look_l.size(); ++i){
        if(look_l[i] != look_r[i]){
            return look_l[i] < look_r[i];
        }
    }
    return lhs.action < rhs.action;
}