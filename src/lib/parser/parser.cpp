// Copyright 2024 Luis Hsu
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     https://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <ParGen.hpp>
#include <Util.hpp>
#include <exception.hpp>

#include <map>
#include <set>
#include <queue>
#include <vector>
#include <memory>
#include <numeric>
#include <fstream>
#include <sstream>
#include <iostream>
#include <regex>
#include <cmath>
#include <algorithm>
#include <unordered_set>
#include <functional>

#include "parser.hpp"

void Pargen::Parser::generate_header(std::ostream& os){
    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    {
        std::string guard = class_name;
        std::replace(guard.begin(), guard.end(), ':', '_');
        os << "#ifndef ParGen_" << guard << "_guard" << std::endl;
        os << "#define ParGen_" << guard << "_guard" << std::endl;
    }
    os << header_prologue << std::endl;

    os << "#include <map>" << std::endl;
    os << "#include <set>" << std::endl;
    os << "#include <list>" << std::endl;
    os << "#include <string>" << std::endl;
    os << "#include <utility>" << std::endl;
    os << "#include <vector>" << std::endl;
    os << "#include <optional>" << std::endl;
    os << "#include <initializer_list>" << std::endl;
    if(!parent.tokens.empty()){
        os << "#include " << parent.tokens.header_path.filename() << std::endl;
    }
    if(parent.lexer.empty()){
        os << "#include <any>" << std::endl;
    }else{
        os << "#include " << parent.lexer.header_path.filename() << std::endl;
    }

    // pargen namespace
    os << "\nnamespace " << parent.name_space << " {\n" << std::endl;

    // Parser class
    os << "struct " << class_name << " {" << std::endl;
    os << "    " << class_name << "(" << parent.lexer.class_name << "& lexer);" << std::endl;
    os << "    " << return_type << " parse();" << std::endl;
    // Funcs
    for(std::string& func : functions){
        os << func << std::endl;
    }

    size_t term_type = sizeof(size_t);
    {
        TermMap term_map(*this);
        term_type = std::pow(2, std::ceil(std::log2(std::ceil(std::log2(term_map.size()) / CHAR_BIT)))) * CHAR_BIT;
    }
    
    // Members
    for(std::string& member : members){
        os << member << std::endl;
    }
    os << "    constexpr static size_t End = (size_t)-1;" << std::endl;
    os << "    using term_t = uint" << term_type << "_t";
    os << ";" << std::endl;
    if(parent.lexer.empty()){
        os << "    using token_t = std::any;" << std::endl;
        os << "protected:" << std::endl;
    }else{
        if(parent.lexer.return_type.empty()){
            if(parent.tokens.empty()){
                os << "    using token_t = std::any;" << std::endl;
            }else{
                os << "    using token_t = " << parent.tokens.class_name << ";" << std::endl;
            }
        }else{
            os << "    using token_t = " << parent.lexer.return_type << ";" << std::endl;
        }
        os << "protected:" << std::endl;
        os << "    " << parent.lexer.class_name << "& lexer;" << std::endl;
    }
    os << "    using Act = std::pair<size_t, std::vector<bool>>;" << std::endl;
    os << "    using State = std::map<term_t, std::vector<Act>>;" << std::endl;
    os << "    struct Entry;" << std::endl;
    os << "    struct Node {" << std::endl;
    os << "        size_t action;" << std::endl;
    os << "        std::vector<bool> param_toggle;" << std::endl;
    os << "        std::list<Entry> children;" << std::endl;
    os << "        std::list<std::pair<term_t,token_t>> flatten();" << std::endl;
    os << "    };" << std::endl;
    os << "    struct Entry {" << std::endl;
    if(parent.options.dump_tree){
        os << "        static size_t serial;" << std::endl;
        os << "        size_t id;" << std::endl;
    }
    os << "        term_t term;" << std::endl;
    os << "        size_t state;"  << std::endl;
    os << "        size_t branch = 0;"  << std::endl;
    os << "        std::variant<std::monostate, Node, token_t> elem;"  << std::endl;
    os << "    };" << std::endl;
    os << "    struct Stack : public std::list<Entry>{" << std::endl;
    os << "        void push(std::pair<term_t,token_t> token, size_t state){" << std::endl;
    os << "            emplace_front(Entry {";
    if(parent.options.dump_tree){
        os << ".id = Entry::serial++, ";
    }
    os << ".term = token.first, .state = state, .elem = token.second});" << std::endl;
    os << "        }" << std::endl;
    os << "        void reduce(size_t action, std::vector<bool> param_toggle);" << std::endl;
    os << "    };\n" << std::endl;
    os << "    std::list<std::pair<term_t,token_t>> buffer;" << std::endl;
    os << "    static std::vector<State> table;" << std::endl;
    os << "    std::pair<term_t,token_t> fetch();" << std::endl;
    os << "    " << return_type << " expand_tree(Entry&);" << std::endl;
    if(parent.options.dump_tree){
        os << "    void dump_tree(Entry&);" << std::endl;
    }
    os << "};\n" << std::endl;

    // Parse error
    os << "struct ParseError : public std::exception {" << std::endl;
    os << "    ParseError(";
    if(parent.tokens.empty()){
        os << class_name << "::term_t term);" << std::endl;
    }else{
        os << "Position pos, " << class_name << "::term_t term);" << std::endl;
        os << "    Position pos;" << std::endl;
    }
    os << "    std::string msg;" << std::endl;
    os << "    const char* what(){" << std::endl;
    os << "        return msg.c_str();" << std::endl;
    os << "    }" << std::endl;
    os << "};\n" << std::endl;

    // close namespace
    os << "} // namespace " << parent.name_space << std::endl;

    // epilogue
    os << header_epilogue << std::endl;
    os << "#endif " << std::endl;
}

void Pargen::Parser::generate_source(std::ostream& os){

    // Create GLR parser
    GLRParser parser(*this);

    // dump terms
    if(parent.options.debug){
        std::ofstream fout("terms.txt");
        parser.dump_terms(fout);
        fout.close();
    }

    // dump grammars
    if(parent.options.debug){
        std::ofstream fout("grams.txt");
        parser.dump_grammars(fout);
        fout.close();
    }

    // dump states
    if(parent.options.debug){
        std::ofstream fout("states.dot");
        parser.dump_states(fout);
        fout.close();
    }

    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    os << "#include " << header_path << std::endl;
    os << source_prologue << std::endl;

    // includes & namespace
    os << "#include <stack>" << std::endl;
    os << "#include <list>" << std::endl;
    os << "#include <variant>" << std::endl;
    os << "#include <vector>" << std::endl;
    os << "#include <algorithm>" << std::endl;
    os << "#include <array>" << std::endl;
    if(parent.options.dump_tree){
        os << "#include <fstream>" << std::endl;
        os << "#include <queue>" << std::endl;
        os << "#include <map>" << std::endl;
    }

    os << "\nnamespace " << parent.name_space << " {" << std::endl;
    if(!parent.tokens.empty()){
        os << "\nusing namespace " << parent.tokens.name_space << ";\n" << std::endl;
    }

    // constructor
    os << class_name << "::" << class_name << "(" << parent.lexer.class_name << "& lexer) : lexer(lexer) {}\n" << std::endl;

    // Dump tree 
    if(parent.options.dump_tree){
        os << "size_t " << class_name << "::Entry::serial = 0;" << std::endl;
        os << "void " << class_name << "::dump_tree(" << class_name << "::Entry& tree){\n"
                "    static std::map<term_t, std::string> term_map {\n";
        for(auto term_pair : parser.term_map){
            os << "        {" << term_pair.second << ",\"" << term_pair.first << "\"},\n";
        }
        os << "    };\n";
        os << "    std::ofstream fout(\"tree.dot\");\n"
            "    fout << \"graph {\" << std::endl;\n"
            "    std::queue<Entry> node_queue;\n"
            "    node_queue.push(tree);\n"
            "    while(!node_queue.empty()){\n"
            "        Entry& entry = node_queue.front();\n"
            "        fout << \"E\" << entry.id << \" [label=\\\"\" << term_map[entry.term] << \"\\\"];\" << std::endl;\n"
            "        if(std::holds_alternative<Node>(entry.elem)){\n"
            "            Node& node = std::get<Node>(entry.elem);\n"
            "            for(auto it = node.children.begin(); it != node.children.end(); ++it){\n"
            "                fout << \"E\" << entry.id << \" -- E\" << it->id << std::endl;\n"
            "                node_queue.emplace(*it);\n"
            "            }\n"
            "        }\n"
            "        node_queue.pop();\n"
            "    }\n"
            "    fout << \"}\";\n"
            "    fout.close();\n"
            "}\n";
    }

    // fetch
    os << "std::pair<" << class_name << "::term_t, " << class_name << "::token_t> " << class_name << "::fetch(){" << std::endl;
    os << "    if(!buffer.empty()){" << std::endl;
    os << "        auto token = buffer.front();" << std::endl;
    os << "        buffer.pop_front();" << std::endl;
    os << "        return token;" << std::endl;
    os << "    }" << std::endl;
    if(!parent.lexer.empty() && parent.lexer.return_type.empty() && !parent.tokens.empty()){
        os << "    " << parent.tokens.class_name << " res = lexer.get();" << std::endl;
        os << "    return {res.index() + 1, res};" << std::endl;
    }else{
        os << "    /* TODO: return pair as below:" << std::endl;
        std::unordered_set<std::string> nterms;
        std::transform(begin(), end(), std::inserter(nterms, nterms.end()), [](Pargen::Grammar& gram){
            return gram.target;
        });
        for(auto term_pair : parser.term_map){
            if(!nterms.contains(term_pair.first)){
                os << "      {" << term_pair.second << ", " << term_pair.first << "}" << std::endl;
            }
        }
        os << "    */" << std::endl;
    }
    os << "}\n" << std::endl;

    // actions
    std::set<std::string> returns;
    for(size_t action_id = 0; action_id < parser.actions.size(); ++action_id){
        GLRParser::Action& action = parser.actions[action_id];
        std::string return_type = parser.type_map[action.result];
        if(return_type.empty()){
            return_type = "void";
        }else{
            returns.insert(return_type);
        }
        os << "static " << return_type << " action_"<< action_id + 1 << "(" << class_name << "& _this, ";
        bool has_first = false;
        if(!parent.tokens.empty()){
            os << "std::vector<Position> _pos";
            has_first = true;
        }
        for(size_t param_id = 0; param_id < action.params.size(); ++param_id){
            term_t term = action.params[param_id];
            if((!parser.term_map.is_term(term) && parser.type_map[term].empty())
                || (term == TermMap::eof)
            ){
                continue;
            }
            if(has_first){
                os << ", ";
            }else{
                has_first = true;
            }
            if(parser.term_map.is_term(term)){
                os << parent.tokens.name_space << "::" << parser.term_map[term].value();
            }else{
                os << parser.type_map[term];
            }
            os << " _op" << param_id;
        }
        os << "){" << action.body << "\n}" << std::endl;
    }
    os << std::endl;

    // table
    os << "std::vector<" << class_name << "::State> " << class_name << "::table = {" << std::endl;
    for(const GLRParser::State& state : parser.states){
        std::map<term_t, std::list<std::pair<size_t, std::vector<bool>>>> acts;
        // Shift
        for(const std::pair<const term_t, size_t>& edge : state.edges){
            acts[edge.first].emplace_back((edge.second << 1) + 1, std::vector<bool>{});
        }
        // Reduce
        for(const GLRParser::Grammar& prod : state.productions){
            if(prod.dot_pos == prod.depends.size()){
                for(term_t lookahead : prod.lookahead){
                    acts[lookahead].emplace_back((prod.action << 1) & ((size_t)~1), prod.param_toggle);
                }
            }
        }
        // Output state
        os << "    {";
        for(auto act_pair : acts){
            // Term
            os << "{" << act_pair.first << ", {";
            for(std::pair<size_t, std::vector<bool>> act : act_pair.second){
                os << "{" << act.first << ",";
                os << "{";
                for(bool toggle : act.second){
                    os << toggle << ",";
                }
                os << "}";
                os << "},";
            }
            os << "}},";
        }
        os << "}," << std::endl;
    }
    os << "};\n" << std::endl;

    // parse
    os << return_type << " " << class_name << "::parse(){\n"
        "    // Prepare\n"
        "    std::stack<Stack::iterator> branches;\n"
        "    Stack stack;\n"
        "    stack.push(fetch(), 0);\n"
        "    auto throw_error = [&](";
    if(!parent.tokens.empty()){
        os << "token_t token, ";
    }
    os << "term_t term){\n"
        "        if(branches.empty()){\n"
        "            throw ParseError(";
    if(!parent.tokens.empty()){
        os << "token.pos, ";
    }
    os << "term);\n"
        "        }\n"
        "        auto& saved = branches.top();\n"
        "        auto buf_top = buffer.begin();\n"
        "        Stack::iterator new_head = stack.begin();\n"
        "        for(auto it = stack.begin(); (it != stack.end()) && (it != saved); it = std::next(it)){\n"
        "            new_head = it;\n"
        "            if(std::holds_alternative<token_t>(it->elem)){\n"
        "                buffer.emplace(buf_top, it->term, std::get<token_t>(it->elem));\n"
        "            }else{\n"
        "                auto flattened = std::get<Node>(it->elem).flatten();\n"
        "                buffer.insert(buf_top, flattened.begin(), flattened.end());\n"
        "            }\n"
        "        }\n"
        "        new_head->branch += 1;\n"
        "        new_head->term = buffer.front().first;\n"
        "        new_head->elem = buffer.front().second;\n"
        "        buffer.pop_front();\n"
        "        stack.erase(stack.begin(), new_head);\n"
        "    };\n"
        "    // Parse\n"
        "    while(stack.front().state != End){\n"
        "        Entry& entry = stack.front();\n"
        "        State& state = table[entry.state];\n"
        "        if(state.contains(entry.term)){\n"
        "            std::vector<Act>& acts = state[entry.term];\n"
        "            if(entry.branch == 0){\n"
        "                if(acts.size() > 1){\n"
        "                    branches.emplace(std::next(stack.begin()));\n"
        "                }\n"
        "            }else if(entry.branch == acts.size() - 1){\n"
        "                branches.pop();\n"
        "            }\n"
        "            Act& act = acts[entry.branch];\n"
        "            if(act.first & 1){ // Shift\n"
        "                stack.push(fetch(), act.first >> 1);\n"
        "            }else{ // Reduce\n"
        "                if(std::holds_alternative<token_t>(entry.elem)){\n"
        "                    buffer.emplace_front(entry.term, std::get<token_t>(entry.elem));\n"
        "                    stack.pop_front();\n"
        "                }\n"
        "                stack.reduce(act.first >> 1, act.second);\n"
        "            }\n"
        "        }else{\n";
    if(parent.tokens.empty()){
        os << "            throw_error(entry.term);\n";
    }else{
        os << "            Entry* ptr = &entry;\n"
            "            while(std::holds_alternative<Node>(ptr->elem)){\n"
            "                ptr = &std::get<Node>(ptr->elem).children.front();\n"
            "            }\n"
            "            if(std::holds_alternative<token_t>(ptr->elem)){\n"
            "                throw_error(std::get<token_t>(ptr->elem), entry.term);\n"
            "            }else{\n"
            "                throw_error(Token(std::monostate(), Position()), entry.term);\n"
            "            }\n";
    }
    os << "        }\n"
        "    }\n";
    if(parent.options.dump_tree){
        os << "    // Dump tree\n"
            "    dump_tree(stack.back());\n";
    }
    os << "    // Expand tree\n"
        "    return expand_tree(stack.back());\n";
    os << "}\n" << std::endl;

    // reduce
    os << "void " << class_name << "::Stack::reduce(size_t action, std::vector<bool> param_toggle){" << std::endl;
    os << "    static const std::vector<term_t> signatures {";
    for(GLRParser::Action& action : parser.actions){
        os << action.result << ",";
    }
    os << "};" << std::endl;
    os << "    if(action == 0){\n"
        "        emplace_front(Entry {.term = 0, .state = End});\n"
        "        return;\n"
        "    }\n"
        "    Node node = {.action = action, .param_toggle = param_toggle};\n"
        "    size_t param_count = std::count_if(param_toggle.begin(), param_toggle.end(), [](bool val){return val;});\n"
        "    for(size_t i = 0; i < param_count; ++i){\n"
        "        node.children.emplace_front(front());\n"
        "        pop_front();\n"
        "    }\n"
        "    Entry* head = &node.children.front();\n"
        "    while(std::holds_alternative<Node>(head->elem)){\n"
        "        Node& child = std::get<Node>(head->elem);\n"
        "        head = &child.children.front();\n"
        "    }\n"
        "    Entry& entry = emplace_front();\n";
    if(parent.options.dump_tree){
        os << "    entry.id = Entry::serial++;\n";
    }
    os << "    entry.term = signatures[action - 1];\n"
        "    entry.state = head->state;\n"
        "    entry.elem.emplace<Node>(node);\n";
    os << "}\n" << std::endl;

    // stack item
    os << "using item_t = std::variant<std::monostate,\n"
        "    " << class_name << "::token_t,\n";
    for(auto it = returns.begin(); it != returns.end(); it = std::next(it)){
        os << "    " << *it;
        if(std::next(it) != returns.end()){
            os << ",";
        }
        os << std::endl;
    }
    os << ">;\n" << std::endl;
    
    // expand tree
    os << return_type << " " << class_name << "::expand_tree(Entry& tree){" << std::endl;
    os << "    std::list<std::variant<Node, token_t>> entry_stack;\n"
        "    std::list<std::pair<Position, item_t>> param_stack;\n"
        "    auto extract_entry = [&](Entry& entry){\n"
        "        if(std::holds_alternative<token_t>(entry.elem)){\n"
        "            entry_stack.emplace_front(std::get<token_t>(entry.elem));\n"
        "        }else if(std::holds_alternative<Node>(entry.elem)){\n"
        "            Node& elem = std::get<Node>(entry.elem);\n"
        "            Node& node = std::get<Node>(entry_stack.emplace_front(Node {.action = elem.action, .param_toggle = elem.param_toggle}));\n"
        "            node.children.swap(elem.children);\n"
        "        }\n"
        "    };\n"
        "    extract_entry(tree);\n";

        // invoke action
    os << "    auto invoke_action = [&](Node& node){\n"
        "        std::vector<Position> positions(node.param_toggle.size());\n"
        "        std::vector<item_t> params(node.param_toggle.size());\n"
        "        Position pos;\n"
        "        for(size_t i = node.param_toggle.size(); i > 0; --i){\n"
        "            size_t index = i - 1;\n"
        "            if(node.param_toggle[index]){\n"
        "                positions[index] = param_stack.front().first;\n"
        "                params[index] = param_stack.front().second;\n"
        "                param_stack.pop_front();\n"
        "            }\n"
        "        }\n"
        "        for(size_t i = 0; i < node.param_toggle.size(); ++i){\n"
        "            if(node.param_toggle[i]){\n"
        "                pos = positions[i];\n"
        "                break;\n"
        "            }\n"
        "        }\n"
        "        switch(node.action){\n";
    for(size_t action_id = 0; action_id < parser.actions.size(); ++action_id){
        GLRParser::Action& action = parser.actions[action_id];
        bool is_void = parser.type_map[action.result].empty();
        os << "            case " << action_id + 1 << ": " << std::endl;
        os << "                param_stack.emplace_front(pos, ";
        if(is_void){
            os << "std::monostate());\n"
                << "                ";
        }
        os << "action_" << action_id + 1 << "(*this, positions";
        for(size_t param_id = 0; param_id < action.params.size(); ++param_id){
            term_t term = action.params[param_id];
            if(term == TermMap::eof){
                continue;
            }
            std::string type;
            bool is_term = false;
            if(parser.term_map.is_term(term)){
                type = parent.tokens.name_space + "::" + parser.term_map[term].value();
                is_term = true;
            }else{
                type = parser.type_map[term];
            }
            if(!type.empty()){
                os << ",\n";
                os << "                    node.param_toggle[" << param_id << "] ? std::get<" << type
                    << ">(";
                if(is_term){
                    os << "std::get<Token>(params[" << param_id << "]))";
                }else{
                    os << "params[" << param_id << "])";
                }
                os << " : " << type << "()";
            }
        }
        os << "\n                )";
        if(is_void){
            os << ";" << std::endl;
        }else{
            os << ");" << std::endl;
        }
        os << "            break;" << std::endl;
    }
    os << "            default:\n"
        "            break;\n"
        "        }\n"
        "    };\n";
    os << "    while(!entry_stack.empty()){\n"
        "        std::variant<Node, token_t>& entry = entry_stack.front();\n"
        "        if(std::holds_alternative<token_t>(entry)){\n"
        "            token_t token = std::get<token_t>(entry);\n"
        "            param_stack.emplace_front(token.pos, token);\n"
        "            entry_stack.pop_front();\n"
        "        }else if(std::holds_alternative<Node>(entry)){\n"
        "            Node& node = std::get<Node>(entry);\n"
        "            if(node.children.size() > 0){\n"
        "                for(auto it = node.children.rbegin(); it != node.children.rend(); it = std::next(it)){\n"
        "                    extract_entry(*it);\n"
        "                }\n"
        "                node.children.clear();\n"
        "            }else{\n"
        "                invoke_action(node);\n"
        "                entry_stack.pop_front();\n"
        "            }\n"
        "        }\n"
        "    }\n";
    if(return_type != "void"){
        os << "    return std::get<" << return_type << ">(param_stack.front().second);" << std::endl;
    }
    os << "}\n" << std::endl;

    // functions
    for(std::string func : functions){
        // Write function
        std::string signature = append_func_name(func, class_name);
        if(signature.starts_with("template")){
            os << "// TODO: " << signature << "\n" << std::endl;
        }else{
            os << signature << "{" << std::endl;
            os << "    // TODO: implement function here" << std::endl;
            os << "}\n" << std::endl;
        }
    }

    // flatten
    os << "std::list<std::pair<" << class_name << "::term_t," << class_name << "::token_t>> " << class_name << "::Node::flatten(){" << std::endl;
    os << "    std::list<std::pair<term_t,token_t>> results;" << std::endl;
    os << "    for(Entry& child : children){" << std::endl;
    os << "        if(std::holds_alternative<token_t>(child.elem)){" << std::endl;
    os << "            results.emplace_back(child.term, std::get<token_t>(child.elem));" << std::endl;
    os << "        }else{" << std::endl;
    os << "            auto flattened = std::get<Node>(child.elem).flatten();" << std::endl;
    os << "            results.insert(results.end(), flattened.begin(), flattened.end());" << std::endl;
    os << "        }" << std::endl;
    os << "    }" << std::endl;
    os << "    return results;" << std::endl;
    os << "}\n" << std::endl;

    // parse error
    std::vector<std::pair<std::string, term_t>> term_list(parser.term_map.begin(), parser.term_map.end());
    std::sort(term_list.begin(), term_list.end(),
        [](const std::pair<std::string, term_t>& lhs, const std::pair<std::string, term_t>& rhs){
            return lhs.second < rhs.second;
        }
    );
    os << parent.name_space << "::ParseError::ParseError(";
    if(!parent.tokens.empty()){
        os << "Position pos, ";
    }
    os << class_name << "::term_t term)";
    if(!parent.tokens.empty()){
        os << " : pos(pos) ";
    }
    os << "{" << std::endl;
    os << "    static const std::vector<std::string> terms {" << std::endl;
    for(auto term_pair : term_list){
        os << "        \"" << term_pair.first << "\"," << std::endl;
    }
    os << "    };" << std::endl;
    
    os << "    msg = \"unexpected \" + terms[term];" << std::endl;
    os << "}" << std::endl;

    // close namespace
    os << "} // namespace " << parent.name_space << "\n" << std::endl;

    // epilogue
    os << source_epilogue << std::endl;
}

bool gram_similar(const GLRParser::Grammar& lhs, const GLRParser::Grammar& rhs){
    return (lhs.dot_pos == rhs.dot_pos)
        && (lhs.depends == rhs.depends)
        && (lhs.target == rhs.target)
        && (lhs.action == rhs.action);
}

GLRParser::GLRParser(Pargen::Parser& parser) : term_map(parser), parser(parser) {
    read_grammar();
    create_states();
    // reduce_states();
    create_edges();
}

TermMap::TermMap(Pargen::Parser& parser){
    // Collect terminals
    std::set<std::string> terms, nterms;
    {
        std::set<std::string> all_terms;
        for(Pargen::Grammar gram : parser){
            nterms.insert(gram.target);
            all_terms.insert(gram.depends.begin(), gram.depends.end());
        }
        std::set_difference(all_terms.begin(), all_terms.end(), nterms.begin(), nterms.end(), std::inserter(terms, terms.end()));
    }

    // Assign term_map
    if(parser.parent.tokens.empty()){
        num_term = terms.size() + items.size();
        for(std::string term : terms){
            items.emplace(term, items.size());
        }
    }else{
        num_term = parser.parent.tokens.size() + items.size();
        for(Pargen::Token& token : parser.parent.tokens){
            items.emplace(token.name, items.size());
        }
    }
    for(std::string nterm : nterms){
        items.emplace(nterm, items.size());
    }
}

void GLRParser::read_grammar(){
    // Read grammars
    std::set<term_t> empties;
    for(Pargen::Grammar& gram : parser){
        // target
        term_t target = term_map[gram.target];
        if(target == TermMap::none){
            throw Exception::Exception("unknown terminal '" + gram.target + "'");
        }
        // action
        Action& action = actions.emplace_back();
        action.result = target;
        if(!type_map.contains(target)){
            type_map[target] = gram.type;
        }
        action.body = gram.content;
        // grammar
        if(gram.depends.empty()){
            // Empty grammar
            if(empties.contains(target)){
                throw Exception::Exception("multiple empty grammar for '" + gram.target + "'");
            }
            empties.emplace(target);
        }else{
            Grammar grammar;
            grammar.target = target;
            grammar.action = actions.size();
            std::transform(gram.depends.begin(), gram.depends.end(), std::back_inserter(grammar.depends), [&](std::string& dep){
                if(term_map[dep] == TermMap::none){
                    throw Exception::Exception("unknown terminal '" + dep + "'");
                }
                return term_map[dep];
            });
            action.params.assign(grammar.depends.begin(), grammar.depends.end());
            grammar.param_toggle.resize(grammar.depends.size(), true);
            grammars.emplace_back(grammar);
        }
    }

    // Trace empties
    for(bool modified = true; modified;){
        modified = false;
        for(Grammar& gram : grammars){
            if(!empties.contains(gram.target) && std::all_of(gram.depends.begin(), gram.depends.end(), [&](term_t depend){
                return empties.contains(depend);
            })){
                modified = true;
                empties.emplace(gram.target);
            }
        }
    }

    // Expand empty grammar
    for(auto gram_it = grammars.begin(); gram_it != grammars.end(); gram_it = std::next(gram_it)){
        Grammar& gram = *gram_it;
        std::vector<std::pair<term_t, size_t>> dep_pairs;
        for(size_t dep_idx = 0, tog_idx = 0; tog_idx < gram.param_toggle.size(); ++tog_idx){
            if(gram.param_toggle[dep_idx]){
                dep_pairs.emplace_back(gram.depends[dep_idx], dep_idx);
                dep_idx += 1;
            }
        }
        for(size_t pair_idx = 0; pair_idx < dep_pairs.size(); ++pair_idx){
            if(empties.contains(dep_pairs[pair_idx].first)){
                Grammar new_gram = gram;
                new_gram.depends.erase(new_gram.depends.begin() + pair_idx);
                new_gram.param_toggle[dep_pairs[pair_idx].second] = false;
                if((new_gram.depends.size() > 1 || (new_gram.depends.size() == 1 && new_gram.target != new_gram.depends[0]))
                    && (std::find(grammars.begin(), grammars.end(), new_gram) == grammars.end())
                ){
                    grammars.emplace_back(new_gram);
                }
            }
        }
    }
}

std::map<term_t, std::set<term_t>> GLRParser::create_first_sets(){
    std::map<term_t, std::set<term_t>> first_sets;
    // Insert terminals
    for(auto term_pair : term_map){
        if(!term_pair.first.empty() && term_map.is_term(term_pair.second)){
            first_sets[term_pair.second].emplace(term_pair.second);
        }
    }

    // Initialize non-terminals
    std::set<term_t> modified;
    for(const GLRParser::Grammar& gram : grammars){
        if(term_map.is_term(gram.depends.front())){
            modified.emplace(gram.target);
            first_sets[gram.target].emplace(gram.depends.front());
        }
    }

    // Update non-terminals
    while(!modified.empty()){
        std::set<term_t> checking = modified;
        modified.clear();
        for(const GLRParser::Grammar& gram : grammars){
            if(checking.contains(gram.depends.front())){
                for(term_t term : first_sets[gram.depends.front()]){
                    if(!first_sets[gram.target].contains(term)){
                        modified.emplace(gram.target);
                        first_sets[gram.target].emplace(term);
                    }
                }
            }
        }
    }
    return first_sets;
}

void GLRParser::create_states(){
    std::map<term_t, std::set<term_t>> first_sets = create_first_sets();
    
    // Create grammar map
    std::map<term_t, std::set<Grammar>> gram_map;
    for(Grammar gram : grammars){
        gram_map[gram.target].insert(gram);
    }

    // Create initial state
    if(term_map[parser.start] == TermMap::none){
        throw Exception::Exception("can't find grammar for start");
    }

    std::queue<State> state_queue;
    state_queue.emplace(std::list<Grammar>{{
        .target = TermMap::start,
        .depends = {term_map[parser.start]},
        .lookahead = {TermMap::eof}
    }});
    size_t state_id = 0;
    std::set<Grammar> expanded;
    while(!state_queue.empty()){
        State& state = states.emplace_back(state_queue.front());
        state.id = state_id++;
        state_queue.pop();
        // Expand production
        std::list<Grammar> produced;
        while(state.productions != produced){
            std::set<Grammar> diff;
            std::set_difference(
                state.productions.begin(), state.productions.end(),
                produced.begin(), produced.end(),
                std::inserter(diff, diff.begin())
            );
            produced = state.productions;
            std::list<Grammar> productions = state.productions;
            bool modified = false;
            for(const Grammar& gram : diff){
                term_t nterm = gram.depends[gram.dot_pos];
                if(!term_map.is_term(nterm)){
                    std::set<term_t> lookahead = gram.lookahead;
                    if(gram.dot_pos < (gram.depends.size() - 1)){
                        lookahead = first_sets[gram.depends[gram.dot_pos + 1]];
                    }
                    for(Grammar prod : gram_map[nterm]){
                        auto liked = std::find_if(productions.begin(), productions.end(), [&](const Grammar& value){
                            return gram_similar(value, prod);
                        });
                        if(liked != productions.end()){
                            liked->lookahead.insert(lookahead.begin(), lookahead.end());
                        }else{
                            prod.lookahead = lookahead;
                            productions.emplace_back(prod);
                        }
                    }
                    modified = true;
                }
            }
            if(modified){
                productions.sort();
                state.productions.swap(productions);
            }
        }
        // Expand states
        std::map<term_t, std::set<Grammar>> prod_map;
        for(Grammar prod : state.productions){
            if(prod.dot_pos != prod.depends.size()){
                term_t key = prod.depends[prod.dot_pos];
                prod.dot_pos += 1;
                if(!expanded.contains(prod)){
                    prod_map[key].emplace(prod);
                    expanded.emplace(prod);
                }
            }else{
                expanded.emplace(prod);
            }
        }
        // Push new states into queue
        for(auto prod_pair : prod_map){
            state_queue.emplace(std::list<Grammar>(prod_pair.second.begin(), prod_pair.second.end()));
        }
    }
}

void GLRParser::create_edges(){
    states.sort([](const State& lhs, const State& rhs){
        return lhs.id < rhs.id;
    });
    // Create state map & id
    std::map<Grammar, size_t> state_map;
    for(auto state_it = states.begin(); state_it != states.end(); state_it = std::next(state_it)){
        for(const Grammar& prod : state_it->productions){
            if(prod.dot_pos != 0){
                state_map[prod] = state_it->id;
            }
        }
    }
    // Create edges
    for(State& state : states){
        for(Grammar prod : state.productions){
            if(prod.dot_pos != prod.depends.size()){
                term_t term = prod.depends[prod.dot_pos];
                prod.dot_pos += 1;
                if(!state_map.contains(prod)){
                    std::stringstream ss;
                    print_grammar(ss, prod) << "' not found while create edge, skipped!";
                    Exception::Warning(std::string("grammar '") + ss.str());
                    continue;
                }
                if(state.edges.contains(term) && (state.edges[term] != state_map[prod])){ // Conflict
                    std::stringstream ss;
                    ss << "state [" << state.id << "]: grammar '";
                    print_grammar(ss, prod) << "' conflict between '" << state.edges[term] << "' and '" << state_map[prod] << "', skipped";
                    Exception::Warning(ss.str());
                }else{
                    state.edges[term] = state_map[prod];
                }
            }
        }
    }
}

void GLRParser::reduce_states(){
    bool modified = true;
    while(modified){
        modified = false;
        states.sort([](const State& lhs, const State& rhs){
            return lhs.productions.size() > rhs.productions.size();
        });
        for(auto lhs_it = states.begin(); lhs_it != states.end(); lhs_it = std::next(lhs_it)){
            for(auto rhs_it = std::next(lhs_it); rhs_it != states.end();){
                auto cur_it = rhs_it;
                rhs_it = std::next(rhs_it);
                std::list<std::pair<std::list<Grammar>::iterator, std::set<term_t>>> intersect;
                for(const Grammar& cur : cur_it->productions){
                    auto found = std::find_if(
                        lhs_it->productions.begin(), lhs_it->productions.end(),
                        [&](const Grammar& lhs){
                            return gram_similar(lhs, cur);
                        }
                    );
                    if(found != lhs_it->productions.end()){
                        intersect.emplace_back(found, cur.lookahead);
                    }
                }
                if(intersect.size() == cur_it->productions.size()){
                    // mergeable
                    std::cout << "Merge " << lhs_it->id << " and " << cur_it->id << std::endl;
                    for(auto inter_pair : intersect){
                        inter_pair.first->lookahead.insert(inter_pair.second.begin(), inter_pair.second.begin());
                    }
                    states.erase(cur_it);
                    modified = true;
                }
            }
        }
    }
}

GLRParser::State::State(std::list<Grammar> productions) : productions(productions){
}

bool operator<(const GLRParser::Grammar& lhs, const GLRParser::Grammar& rhs){
    if(lhs.dot_pos != rhs.dot_pos){
        return lhs.dot_pos < rhs.dot_pos;
    }
    if(lhs.depends != rhs.depends){
        return lhs.depends < rhs.depends;
    }
    if(lhs.target != rhs.target){
        return lhs.target < rhs.target;
    }
    return lhs.lookahead < rhs.lookahead;
}

bool operator<(const GLRParser::State& lhs, const GLRParser::State& rhs){
    return lhs.productions < rhs.productions;
}