// Copyright 2024 Luis Hsu
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     https://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <ParGen.hpp>
#include <Util.hpp>
#include <exception.hpp>

#include <map>
#include <set>
#include <deque>
#include <vector>
#include <memory>
#include <fstream>
#include <sstream>
#include <regex>
#include <algorithm>
#include <unordered_set>

#include "parser.hpp"

void Pargen::Parser::generate_header(std::ostream& os){
    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    {
        std::string guard = class_name;
        std::replace(guard.begin(), guard.end(), ':', '_');
        os << "#ifndef ParGen_" << guard << "_guard" << std::endl;
        os << "#define ParGen_" << guard << "_guard" << std::endl;
    }
    os << header_prologue << std::endl;

    if(!parent.tokens.empty()){
        os << "#include " << parent.tokens.header_path.filename() << std::endl;
    }
    if(parent.lexer.empty()){
        os << "#include <any>" << std::endl;
    }else{
        os << "#include " << parent.lexer.header_path.filename() << std::endl;
    }

    // pargen namespace
    os << "\nnamespace " << parent.name_space << " {\n" << std::endl;

    // Parser class
    os << "struct " << class_name << " {" << std::endl;
    os << "    " << class_name << "(" << parent.lexer.class_name << "& lexer);" << std::endl;
    os << "    " << return_type << " parse();" << std::endl;
    // Funcs
    for(std::string& func : functions){
        os << func << std::endl;
    }
    // Members
    for(std::string& member : members){
        os << member << std::endl;
    }
    os << "protected:" << std::endl;
    os << "    using term_t = size_t;" << std::endl;
    if(parent.lexer.empty()){
        os << "    using token_t = std::any;" << std::endl;
    }else{
        if(parent.lexer.return_type.empty()){
            if(parent.tokens.empty()){
                os << "    using token_t = std::any;" << std::endl;
            }else{
                os << "    using token_t = " << parent.tokens.class_name << ";" << std::endl;
            }
        }else{
            os << "    using token_t = " << parent.lexer.return_type << ";" << std::endl;
        }
        os << "    " << parent.lexer.class_name << "& lexer;" << std::endl;
    }
    os << "    std::pair<term_t,token_t> fetch();" << std::endl;
    os << "};\n" << std::endl;

    // close namespace
    os << "} // namespace " << parent.name_space << std::endl;

    // epilogue
    os << header_epilogue << std::endl;
    os << "#endif " << std::endl;
}

void Pargen::Parser::generate_source(std::ostream& os){

    // Create GLR parser
    GLRParser parser(*this);

    // dump terms
    if(parent.options.debug){
        std::ofstream fout("terms.txt");
        parser.dump_terms(fout);
        fout.close();
    }

    // dump grammars
    if(parent.options.debug){
        std::ofstream fout("grams.txt");
        parser.dump_grammars(fout);
        fout.close();
    }

    // dump states
    if(parent.options.debug){
        std::ofstream fout("states.dot");
        parser.dump_states(fout);
        fout.close();
    }

    // prologue
    os << "/** generated by ParGen **/" << std::endl;
    os << "#include " << header_path << std::endl;
    os << source_prologue << std::endl;

    // includes & namespace
    os << "\nnamespace " << parent.name_space << " {" << std::endl;
    if(!parent.tokens.empty()){
        os << "\nusing namespace " << parent.tokens.name_space << ";\n" << std::endl;
    }

    // constructor
    os << class_name << "::" << class_name << "(" << parent.lexer.class_name << "& lexer) : lexer(lexer) {}\n" << std::endl;

    // fetch
    os << "std::pair<" << class_name << "::term_t, " << class_name << "::token_t> " << class_name << "::fetch(){" << std::endl;
    if(!parent.lexer.empty() && parent.lexer.return_type.empty() && !parent.tokens.empty()){
        os << "    " << parent.tokens.class_name << " res = lexer.get();" << std::endl;
        os << "    return {res.index(), res};" << std::endl;
    }else{
        os << "    /* TODO: return pair as below:" << std::endl;
        std::unordered_set<std::string> nterms;
        std::transform(begin(), end(), std::inserter(nterms, nterms.end()), [](Pargen::Grammar& gram){
            return gram.target;
        });
        for(auto term_pair : parser.term_map){
            if(!nterms.contains(term_pair.first)){
                os << "      {" << term_pair.second << ", " << term_pair.first << "}" << std::endl;
            }
        }
        os << "    */" << std::endl;
    }
    os << "}\n" << std::endl;

    // parse
    os << "void " << class_name << "::parse(){" << std::endl;
    
    os << "}\n" << std::endl;

    // functions
    for(std::string func : functions){
        // Write function
        std::string signature = append_func_name(func, class_name);
        if(signature.starts_with("template")){
            os << "// TODO: " << signature << "\n" << std::endl;
        }else{
            os << signature << "{" << std::endl;
            os << "    // TODO: implement function here" << std::endl;
            os << "}\n" << std::endl;
        }
    }

    // close namespace
    os << "} // namespace " << parent.name_space << "\n" << std::endl;

    // epilogue
    os << source_epilogue << std::endl;
}

GLRParser::GLRParser(Pargen::Parser& parser) : term_map(create_term_map(parser)), parser(parser) {
    // Prepare grammar
    read_grammar();
    std::map<term_t, std::set<term_t>> first_sets = create_first_sets();
    // Create grammar map
    std::map<term_t, std::set<Grammar>> gram_map;
    for(Grammar gram : grammars){
        gram_map[gram.target].insert(gram);
    }
    // Create states
    if(term_map[parser.start] == TermMap::none){
        throw Exception::Exception("can't find grammar for start");
    }
    std::deque<Grammar> gram_queue {Grammar {
        .target = TermMap::start,
        .depends = {term_map[parser.start]},
        .lookahead = {TermMap::eof}
    }};
    std::set<Grammar> created;
    while(!gram_queue.empty()){
        State state(gram_queue.front(), gram_map, first_sets);
        gram_queue.pop_front();
        if(!created.contains(state.productions.front())){
            created.emplace(state.productions.front());
        // if(std::none_of(states.begin(), states.end(), [&](State& existing){
        //     return state.try_merge(existing);
        // })){
            states.emplace_back(state);
            for(Grammar gram : state.productions){
                if(gram.dot_pos != gram.depends.size()){
                    gram.dot_pos += 1;
                    gram_queue.push_back(gram);
                }
            }
        }
    }
}

TermMap GLRParser::create_term_map(Pargen::Parser& parser){
    // Collect terminals
    std::set<std::string> terms, nterms;
    {
        std::set<std::string> all_terms;
        for(Pargen::Grammar gram : parser){
            nterms.insert(gram.target);
            all_terms.insert(gram.depends.begin(), gram.depends.end());
        }
        std::set_difference(all_terms.begin(), all_terms.end(), nterms.begin(), nterms.end(), std::inserter(terms, terms.end()));
    }

    // Assign term_map
    if(parser.parent.tokens.empty()){
        return TermMap(std::vector<std::string>(terms.begin(), terms.end()), nterms);
    }else{
        std::vector<std::string> tokens;
        for(Pargen::Token& token : parser.parent.tokens){
            tokens.emplace_back(token.name);
        }
        return TermMap(tokens, nterms);
    }
}

void GLRParser::read_grammar(){
    // Read grammars
    std::set<term_t> empties;
    for(Pargen::Grammar& gram : parser){
        if(gram.depends.empty()){
            // Empty grammar
            if(term_map[gram.target] == TermMap::none){
                throw Exception::Exception("unknown terminal '" + gram.target + "'");
            }
            empties.emplace(term_map[gram.target]);
        }else{
            Grammar grammar;
            grammar.target = term_map[gram.target];
            grammar.action = actions.size();
            actions.emplace_back(gram.content);
            std::transform(gram.depends.begin(), gram.depends.end(), std::back_inserter(grammar.depends), [&](std::string& dep){
                if(term_map[dep] == TermMap::none){
                    throw Exception::Exception("unknown terminal '" + dep + "'");
                }
                return term_map[dep];
            });
            grammars.emplace(grammar);
        }
    }

    // Expand empty grammar
    for(auto gram_it = grammars.begin(); gram_it != grammars.end(); gram_it = std::next(gram_it)){
        Grammar gram = *gram_it;
        for(size_t dep_idx = 0; dep_idx < gram.depends.size(); ++dep_idx){
            if(empties.contains(gram.depends[dep_idx])){
                Grammar new_gram = gram;
                new_gram.depends.erase(new_gram.depends.begin() + dep_idx);
                if((new_gram.depends.size() > 1 || (new_gram.depends.size() == 1 && new_gram.target != new_gram.depends[0]))
                    && std::find(grammars.begin(), grammars.end(), new_gram) == grammars.end()
                ){
                    grammars.emplace(new_gram);
                }
            }
        }
    }
}

std::map<term_t, std::set<term_t>> GLRParser::create_first_sets(){
    std::map<term_t, std::set<term_t>> first_sets;
    // Insert terminals
    for(auto term_pair : term_map){
        if(!term_pair.first.empty() && term_map.is_term(term_pair.second)){
            first_sets[term_pair.second].emplace(term_pair.second);
        }
    }

    // Initialize non-terminals
    std::set<term_t> modified;
    for(const GLRParser::Grammar& gram : grammars){
        if(term_map.is_term(gram.depends.front())){
            modified.emplace(gram.target);
            first_sets[gram.target].emplace(gram.depends.front());
        }
    }

    // Update non-terminals
    while(!modified.empty()){
        std::set<term_t> checking = modified;
        modified.clear();
        for(const GLRParser::Grammar& gram : grammars){
            if(checking.contains(gram.depends.front())){
                for(term_t term : first_sets[gram.depends.front()]){
                    if(!first_sets[gram.target].contains(term)){
                        modified.emplace(gram.target);
                        first_sets[gram.target].emplace(term);
                    }
                }
            }
        }
    }
    return first_sets;
}

GLRParser::State::State(Grammar grammar, std::map<term_t, std::set<Grammar>>& gram_map, std::map<term_t, std::set<term_t>>& first_sets){

    // Insert grammar
    std::set<Grammar> produced {grammar};
    productions.emplace_back(grammar);
    // Expand productions
    if(grammar.dot_pos != grammar.depends.size()){
        for(Grammar& prod : productions){
            // lookahead
            std::set<term_t> lookahead(prod.lookahead.begin(), prod.lookahead.end());
            if(prod.dot_pos < prod.depends.size() - 1){
                lookahead = first_sets[prod.depends[prod.dot_pos + 1]];
            }
            // produce grammar
            for(Grammar gram : gram_map[prod.depends[prod.dot_pos]]){
                gram.lookahead = lookahead;
                if(!produced.contains(gram)){
                    produced.emplace(gram);
                    productions.emplace_back(gram);
                }
            }
        }
    }
}

bool GLRParser::State::try_merge(State& existing){
    const auto comp = [](const Grammar& lhs, const Grammar& rhs){
        return (lhs.target == rhs.target) && (lhs.dot_pos == rhs.dot_pos) && (lhs.depends == rhs.depends);
    };
    for(Grammar& prod : productions){
        if(std::none_of(existing.productions.begin(), existing.productions.end(), [&](const Grammar& exi){
            return comp(prod, exi);
        })){
            return false;
        }
    }
    for(Grammar& prod : productions){
        auto exist_it = std::find_if(existing.productions.begin(), existing.productions.end(), [&](const Grammar& exi){
            return comp(prod, exi);
        });
        exist_it->lookahead.insert(prod.lookahead.begin(), prod.lookahead.end());
    }
    return true;
}

std::ostream& GLRParser::print_grammar(std::ostream& os, GLRParser::Grammar& gram){
    os << term_map[gram.target].value() << " :";
    for(size_t i = 0; i < gram.depends.size(); ++i){
        if(i == gram.dot_pos){
            os << " .";
        }
        os << " " << term_map[gram.depends[i]].value();
    }
    if(gram.dot_pos == gram.depends.size()){
        os << " .";
    }
    if(!gram.lookahead.empty()){
        os << " (";
        for(term_t look : gram.lookahead){
            os << term_map[look].value() << ",";
        }
        os << ")";
    }
    if(gram.action){
        os << " [" << gram.action.value() << "]";
    }
    return os;
}

std::ostream& GLRParser::dump_terms(std::ostream& os){
    std::vector<std::pair<std::string, term_t>> term_list(term_map.begin(), term_map.end());
    std::sort(term_list.begin(), term_list.end(),
        [](const std::pair<std::string, term_t>& lhs, const std::pair<std::string, term_t>& rhs){
            return lhs.second < rhs.second;
        }
    );
    for(std::pair<std::string, term_t>& term_pair : term_list){
        os << "[" << (term_map.is_term(term_pair.second) ? "term" : "non-term") << "] "
            << term_pair.second << "," << term_pair.first << std::endl;
    }
    return os;
}

std::ostream& GLRParser::dump_grammars(std::ostream& os){
    for(Grammar gram : grammars){
        print_grammar(os, gram) << std::endl;
    }
    return os;
}

std::ostream& GLRParser::dump_states(std::ostream& os){
    os << "digraph {" << std::endl;
    os << "    rankdir=LR;" << std::endl;
    os << "    node [shape=record];" << std::endl;
    size_t state_id = 0;
    for(State& state : states){
        os << "S" << state_id << " [label=\"S" << state_id;
        size_t prod_id = 0;
        for(Grammar& prod : state.productions){
            os << "|<g" << prod_id << "> ";
            std::stringstream ss;
            print_grammar(ss, prod);
            os << std::regex_replace(ss.str(), std::regex(" "), "&#92; ");
        }
        os << "\"];" << std::endl;
        state_id += 1;
    }
    os << "}" << std::endl;
    return os;
}

bool operator<(const GLRParser::Grammar& lhs, const GLRParser::Grammar& rhs){
    if(lhs.target != rhs.target){
        return lhs.target < rhs.target;
    }
    if(lhs.depends.size() != rhs.depends.size()){
        return lhs.depends.size() < rhs.depends.size();
    }
    for(size_t i = 0; i < lhs.depends.size(); ++i){
        if(lhs.depends[i] != rhs.depends[i]){
            return lhs.depends[i] < rhs.depends[i];
        }
    }
    if(lhs.dot_pos != rhs.dot_pos){
        return lhs.dot_pos < rhs.dot_pos;
    }
    if(lhs.lookahead.size() != rhs.lookahead.size()){
        return lhs.lookahead.size() < rhs.lookahead.size();
    }
    std::vector<term_t> look_l(lhs.lookahead.begin(), lhs.lookahead.end());
    std::sort(look_l.begin(), look_l.end());
    std::vector<term_t> look_r(rhs.lookahead.begin(), rhs.lookahead.end());
    std::sort(look_r.begin(), look_r.end());
    for(size_t i = 0; i < look_l.size(); ++i){
        if(look_l[i] != look_r[i]){
            return look_l[i] < look_r[i];
        }
    }
    if(lhs.action.has_value() && rhs.action.has_value()){
        return lhs.action.value() < rhs.action.value();
    }
    return !lhs.action.has_value() && rhs.action.has_value();
}